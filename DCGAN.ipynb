{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nimport torchvision.utils as vutils\n\nimport matplotlib.pyplot as plt\nimport random\nimport numpy as np\nimport timeit\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-15T15:35:07.727879Z","iopub.execute_input":"2023-11-15T15:35:07.728151Z","iopub.status.idle":"2023-11-15T15:35:11.593635Z","shell.execute_reply.started":"2023-11-15T15:35:07.728125Z","shell.execute_reply":"2023-11-15T15:35:11.592687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/celeba-dataset/img_align_celeba\"\nBATCH_SIZE = 1024\nIMG_SIZE = 64\nCHANNELS = 3\nINPUT_VECTOR_DIM = 100\nFEATURE_MAP_DIM = 64\nLR = 2e-4\nBETA1 = 0.5\nEPOCHS = 2\nRANDOM_SEED = 42\n\nrandom.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed_all(RANDOM_SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:35:11.595410Z","iopub.execute_input":"2023-11-15T15:35:11.595818Z","iopub.status.idle":"2023-11-15T15:35:11.630027Z","shell.execute_reply.started":"2023-11-15T15:35:11.595791Z","shell.execute_reply":"2023-11-15T15:35:11.629166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, feature_map_dim, channels):\n        super(Discriminator, self).__init__()\n        self.conv_1 = nn.Conv2d(channels, feature_map_dim*2, 4, 2, 1, bias=False) #size [128, 32, 32]\n        self.conv_2 = nn.Conv2d(feature_map_dim*2, feature_map_dim*4, 4, 2, 1, bias=False) #size [256, 16, 16]\n        self.conv_3 = nn.Conv2d(feature_map_dim*4, feature_map_dim*8, 4, 2, 1, bias=False) #size [512, 8, 8]\n        self.conv_4 = nn.Conv2d(feature_map_dim*8, feature_map_dim*16, 4, 2, 1, bias=False) #size [1024, 4, 4]\n        self.conv_5 = nn.Conv2d(feature_map_dim*16, 1, 4, 1, 0, bias=False) #size [1, 1, 1]\n        \n        self.leaky_relu = nn.LeakyReLU(0.2)\n        \n        self.batch_norm_1 = nn.BatchNorm2d(feature_map_dim*4)\n        self.batch_norm_2 = nn.BatchNorm2d(feature_map_dim*8)\n        self.batch_norm_3 = nn.BatchNorm2d(feature_map_dim*16)\n\n        self.sigmoid = nn.Sigmoid()\n        \n\n    def forward(self, inp):\n        x = self.conv_1(inp)\n        x = self.leaky_relu(x)\n        \n        x = self.conv_2(x)\n        x = self.batch_norm_1(x)\n        x = self.leaky_relu(x)\n        \n        x = self.conv_3(x)\n        x = self.batch_norm_2(x)\n        x = self.leaky_relu(x)\n        \n        x = self.conv_4(x)\n        x = self.batch_norm_3(x)\n        x = self.leaky_relu(x)\n        \n        x = self.conv_5(x)\n        out = self.sigmoid(x)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:35:11.631220Z","iopub.execute_input":"2023-11-15T15:35:11.631859Z","iopub.status.idle":"2023-11-15T15:35:11.642114Z","shell.execute_reply.started":"2023-11-15T15:35:11.631832Z","shell.execute_reply":"2023-11-15T15:35:11.641184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = Discriminator(FEATURE_MAP_DIM, CHANNELS).to(device)\n\nx = torch.randn(BATCH_SIZE, CHANNELS, IMG_SIZE, IMG_SIZE).to(device)\ndis_out = discriminator(x)\nprint(dis_out.size())","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:35:11.644035Z","iopub.execute_input":"2023-11-15T15:35:11.644864Z","iopub.status.idle":"2023-11-15T15:35:19.615110Z","shell.execute_reply.started":"2023-11-15T15:35:11.644838Z","shell.execute_reply":"2023-11-15T15:35:19.614200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, input_vector_dim, feature_map_dim, channels):\n        super(Generator, self).__init__()\n        self.convt_1 = nn.ConvTranspose2d(input_vector_dim, feature_map_dim*16, 4, 1, 0, bias=False) #size [1024, 4, 4]\n        self.convt_2 = nn.ConvTranspose2d(feature_map_dim*16, feature_map_dim*8, 4, 2, 1, bias=False) #size [512, 8, 8]\n        self.convt_3 = nn.ConvTranspose2d(feature_map_dim*8, feature_map_dim*4, 4, 2, 1, bias=False) #size [256, 16, 16]\n        self.convt_4 = nn.ConvTranspose2d(feature_map_dim*4, feature_map_dim*2, 4, 2, 1, bias=False) #size [128, 32, 32]\n        self.convt_5 = nn.ConvTranspose2d(feature_map_dim*2, channels, 4, 2, 1, bias=False) #size [3, 64, 64]\n        \n        self.relu = nn.ReLU()\n        \n        self.batch_norm_1 = nn.BatchNorm2d(feature_map_dim*16)\n        self.batch_norm_2 = nn.BatchNorm2d(feature_map_dim*8)\n        self.batch_norm_3 = nn.BatchNorm2d(feature_map_dim*4)\n        self.batch_norm_4 = nn.BatchNorm2d(feature_map_dim*2)\n        \n        self.tanh = nn.Tanh()\n\n    def forward(self, inp):\n        x = self.convt_1(inp)\n        x = self.batch_norm_1(x)\n        x = self.relu(x)\n        \n        x = self.convt_2(x)\n        x = self.batch_norm_2(x)\n        x = self.relu(x)\n        \n        x = self.convt_3(x)\n        x = self.batch_norm_3(x)\n        x = self.relu(x)\n        \n        x = self.convt_4(x)\n        x = self.batch_norm_4(x)\n        x = self.relu(x)\n        \n        x = self.convt_5(x)\n        out = self.tanh(x)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:35:19.616277Z","iopub.execute_input":"2023-11-15T15:35:19.616565Z","iopub.status.idle":"2023-11-15T15:35:19.627691Z","shell.execute_reply.started":"2023-11-15T15:35:19.616540Z","shell.execute_reply":"2023-11-15T15:35:19.626714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = Generator(INPUT_VECTOR_DIM, FEATURE_MAP_DIM, CHANNELS).to(device)\n\nnoise = torch.randn(BATCH_SIZE, INPUT_VECTOR_DIM, 1, 1, device=device)\ngen_out = generator(noise)\nprint(gen_out.size())","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:35:19.628984Z","iopub.execute_input":"2023-11-15T15:35:19.629446Z","iopub.status.idle":"2023-11-15T15:35:19.893155Z","shell.execute_reply.started":"2023-11-15T15:35:19.629413Z","shell.execute_reply":"2023-11-15T15:35:19.892247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = ImageFolder(DATA_DIR,\n                           transform=transforms.Compose([\n                               transforms.Resize(IMG_SIZE),\n                               transforms.CenterCrop(IMG_SIZE),\n                               transforms.ToTensor(),\n                               transforms.Normalize(*((0.5,0.5,0.5),(0.5,0.5,0.5))),\n                           ]))\n\n\ndataloader = DataLoader(dataset, BATCH_SIZE, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:35:19.894096Z","iopub.execute_input":"2023-11-15T15:35:19.894356Z","iopub.status.idle":"2023-11-15T15:38:22.867333Z","shell.execute_reply.started":"2023-11-15T15:35:19.894333Z","shell.execute_reply":"2023-11-15T15:38:22.866373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCELoss()\n\ndiscriminator_optimizer = optim.Adam(discriminator.parameters(), lr=LR, betas=(BETA1, 0.999))\ngenerator_optimizer = optim.Adam(generator.parameters(), lr=LR, betas=(BETA1, 0.999))\n\ngenerator.train()\ndiscriminator.train()\n\nstart = timeit.default_timer()\nfor epoch in tqdm(range(EPOCHS), position=0, leave=True):\n    generator_running_loss = 0\n    discriminator_running_loss = 0\n    for idx, data in enumerate(tqdm(dataloader, position=0, leave=True)):\n        img_data = data[0].to(device) #size [1024, 3, 64, 64]\n        dummy_labels = data[1] #size [1024]\n        \n        real_labels = torch.full((dummy_labels.size()), 1., dtype=torch.float).to(device) #size [1024]\n        fake_labels = torch.full((dummy_labels.size()), 0., dtype=torch.float).to(device)\n        noise = torch.randn(dummy_labels.size()[0], INPUT_VECTOR_DIM, 1, 1).to(device) #size [1024, 100, 1, 1]\n        \n        \n        discriminator_real_out = discriminator(img_data).view(-1) #size [1024] .view(-1) to rid unnecessary dimensions\n        discriminator_real_loss = criterion(discriminator_real_out, real_labels)\n        discriminator.zero_grad()\n        discriminator_real_loss.backward()\n        \n        generator_fake_out = generator(noise) #size [1024, 3, 64, 64]\n        discriminator_fake_out = discriminator(generator_fake_out.detach()).view(-1) #detach used because we'll calculate it for a second time\n        discriminator_fake_loss = criterion(discriminator_fake_out, fake_labels) \n        discriminator_fake_loss.backward()\n        discriminator_running_loss += discriminator_real_loss.item() + discriminator_fake_loss.item()\n        discriminator_optimizer.step()\n\n        discriminator_fake_out = discriminator(generator_fake_out).view(-1) #calculated it for a second time. So that we won't have to backward graphs a second time\n        generator_loss = criterion(discriminator_fake_out, real_labels)\n        generator_running_loss += generator_loss.item()\n        generator.zero_grad()\n        generator_loss.backward()\n        generator_optimizer.step()\n        \n    \n    discriminator_loss = discriminator_running_loss / 2*(idx + 1)\n    generator_loss = generator_running_loss / (idx + 1)\n    \n    print(f\"Discriminator Loss EPOCH {epoch+1}: {discriminator_loss:.4f}\")\n    print(f\"Generator Loss EPOCH {epoch+1}: {generator_loss:.4f}\")\n    plt.figure(figsize=(10,10))\n    plt.subplot(1,2,1)\n    plt.axis(\"off\")\n    plt.title(f\"Epoch {epoch+1} Generated Images\")\n    plt.imshow(np.transpose(vutils.make_grid(generator_fake_out[:9], padding=5, normalize=True, nrow=3).cpu(),(1,2,0)))\n    plt.show()\n    \nstop = timeit.default_timer()\nprint(f\"Training Time: {stop-start:.2f}s\")","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:38:22.868579Z","iopub.execute_input":"2023-11-15T15:38:22.869103Z","iopub.status.idle":"2023-11-15T16:18:54.449371Z","shell.execute_reply.started":"2023-11-15T15:38:22.869069Z","shell.execute_reply":"2023-11-15T16:18:54.448575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:20:35.217336Z","iopub.execute_input":"2023-11-15T16:20:35.218052Z","iopub.status.idle":"2023-11-15T16:20:35.222261Z","shell.execute_reply.started":"2023-11-15T16:20:35.218020Z","shell.execute_reply":"2023-11-15T16:20:35.221305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_batch = next(iter(dataloader))\n\nplt.figure(figsize=(10,10))\nplt.subplot(1,2,1)\nplt.axis(\"off\")\nplt.title(\"Real Images\")\nplt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:9], padding=5, normalize=True, nrow=3).cpu(),(1,2,0)))\n\nplt.figure(figsize=(10,10))\nplt.subplot(1,2,2)\nplt.axis(\"off\")\nplt.title(\"Generated Images\")\nplt.imshow(np.transpose(vutils.make_grid(generator_fake_out[:9], padding=5, normalize=True, nrow=3).cpu(),(1,2,0)))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:22:13.775533Z","iopub.execute_input":"2023-11-15T16:22:13.776437Z","iopub.status.idle":"2023-11-15T16:22:16.886302Z","shell.execute_reply.started":"2023-11-15T16:22:13.776400Z","shell.execute_reply":"2023-11-15T16:22:16.885330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise = torch.randn(dummy_labels.size()[0], INPUT_VECTOR_DIM, 1, 1).to(device)\ngenerator_fake_out = generator(noise)\n\nplt.imshow(generator_fake_out[5].detach().cpu().permute(1, 2, 0))","metadata":{"execution":{"iopub.status.busy":"2023-11-15T16:23:38.146007Z","iopub.execute_input":"2023-11-15T16:23:38.146356Z","iopub.status.idle":"2023-11-15T16:23:38.763574Z","shell.execute_reply.started":"2023-11-15T16:23:38.146328Z","shell.execute_reply":"2023-11-15T16:23:38.762717Z"},"trusted":true},"execution_count":null,"outputs":[]}]}